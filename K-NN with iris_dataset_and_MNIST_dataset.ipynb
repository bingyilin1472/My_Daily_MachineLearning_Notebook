{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## K-NN(K-Nearest Neighbors) with iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset description\n",
    "- sklearn dataset has itself data type like python dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "print(type(iris))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dimension: 150 rows, 4 columns\n",
    "- features_key: data, target_key: target"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iris Dataset Description\n",
    "- There are four attribute with numeric values.\n",
    "- This is a classification task: target variable has 3 classes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iris Dataset structure"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys:  dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      "Shape:  (150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Keys: \" ,iris.keys())\n",
    "print(\"Shape: \",iris.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Iris field mapping and first 5 records\n",
    "- enumerate function would return index and value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'sepal length (cm)', 1: 'sepal width (cm)', 2: 'petal length (cm)', 3: 'petal width (cm)'}\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[5.1, 3.5, 1.4, 0.2],\n       [4.9, 3. , 1.4, 0.2],\n       [4.7, 3.2, 1.3, 0.2],\n       [4.6, 3.1, 1.5, 0.2],\n       [5. , 3.6, 1.4, 0.2]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_index_to_class = {i:c for i,c in enumerate(iris.feature_names)}\n",
    "print(iris_index_to_class)\n",
    "iris.data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category mapping\n",
    "- 0: setosa\n",
    "- 1: versicolor\n",
    "- 2: virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([0, 1, 2])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all categories\n",
    "print(iris.target_names)\n",
    "# use np.unique method to show all categories\n",
    "np.unique(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- iris_data: predictive data\n",
    "- iris_target: labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "iris_data = iris.data\n",
    "iris_target = iris.target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hold-out set for final evaluation/validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_data, test_data, train_target, test_target = train_test_split(\n",
    "    iris_data, iris_target, test_size = 0.4, random_state=0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(90, 4)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data Splitting for model selection/evaluation\n",
    "- 8 : 2 = training set : testing set\n",
    "- By convention, the ratio 7:3 and 8:2 both are frequently used for splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_data 90\n",
      "Length of test_data 60\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of train_data\", len(train_data))\n",
    "print(\"Length of test_data\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "KNeighborsClassifier(n_neighbors=6)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "knn.fit(train_data, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 1 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 2 1 1 2 0 2 0 0 1 2 2 1 2 1 2 1 1 2 1 1 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "iris_test_prediction = knn.predict(test_data)\n",
    "print(iris_test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Performance : accuracy, macro & micro averages\n",
    "- accuracy is the the number of correct predictions / the number of test data\n",
    "- Because of multi-classes in the target, we also use micro and macro averaging to est\n",
    "    - Acc, micro avg and macro avg are all very close. That means all our target classes' distribution are balanced in our\n",
    "    dataset. So we can just use accuracy to estimate our model performance.\n",
    "- In this case, there might be high possibility about over-fitting, because our sample is too small and testing set is\n",
    "similar to training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn accuracy of iris training dataset: 0.9166666666666666\n",
      "knn accuracy with iris dataset:        0.9166666666666666\n",
      "knn macro average with iris dataset:   0.9220151828847482\n",
      "knn micro average with iris dataset:   0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "iris_acc_training_set = knn.score(train_data, train_target)\n",
    "iris_acc = knn.score(test_data, test_target)\n",
    "iris_macro_avg = recall_score(test_target, iris_test_prediction, average='macro')\n",
    "iris_micro_avg = recall_score(test_target, iris_test_prediction, average='micro')\n",
    "print('knn accuracy of iris training dataset:', iris_acc)\n",
    "print('knn accuracy with iris dataset:       ', iris_acc)\n",
    "print('knn macro average with iris dataset:  ', iris_macro_avg)\n",
    "print('knn micro average with iris dataset:  ', iris_micro_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sklearn.metric.classification_report\n",
    "- This module let us show all classification task metrics we need.\n",
    "    - precision, recall, f1, accuracy, micro avg, macro avg ... This is a easy way to achieve these all metrics in one\n",
    "    statement.\n",
    "    - In this case there is no micro avg. It is removed automatically because it is equal to accuracy."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        16\n",
      "  versicolor       0.85      0.96      0.90        23\n",
      "   virginica       0.94      0.81      0.87        21\n",
      "\n",
      "    accuracy                           0.92        60\n",
      "   macro avg       0.93      0.92      0.92        60\n",
      "weighted avg       0.92      0.92      0.92        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# labels order must be mapped the target names\n",
    "print(classification_report(test_target, iris_test_prediction,target_names= iris.target_names, labels=[0,1,2]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_neighbor = [6, 10, 15, 20, 30, 50, 70, 90]\n",
    "r_performance = []\n",
    "for n in n_neighbor:\n",
    "    knn_forSelect =KNeighborsClassifier(n_neighbors=n)\n",
    "    knn_forSelect.fit(train_data, train_target)\n",
    "    acc_train = knn_forSelect.score(train_data, train_target)\n",
    "    acc_test = knn_forSelect.score(test_data, test_target)\n",
    "    r_performance.append([n, format(acc_train,\".2f\"),\n",
    "    format(acc_test,\".2f\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Show the relationship of over-fitting/under-fitting and n_neighbors\n",
    "We can intuitively get some insights about over/under-fitting from the table below.\n",
    "- n >= 90 is under-fitting, the model ability is too weak to fit the data.\n",
    "- n > 6 is over-fitting, the generation of model is bad for test/unseen data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   # of neighbors acc_train acc_test\n0               6      1.00     0.92\n1              10      0.99     0.97\n2              15      0.97     0.93\n3              20      0.98     0.92\n4              30      0.93     0.87\n5              50      0.92     0.85\n6              70      0.82     0.73\n7              90      0.38     0.27",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th># of neighbors</th>\n      <th>acc_train</th>\n      <th>acc_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>1.00</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10</td>\n      <td>0.99</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15</td>\n      <td>0.97</td>\n      <td>0.93</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20</td>\n      <td>0.98</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>30</td>\n      <td>0.93</td>\n      <td>0.87</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>50</td>\n      <td>0.92</td>\n      <td>0.85</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>70</td>\n      <td>0.82</td>\n      <td>0.73</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>90</td>\n      <td>0.38</td>\n      <td>0.27</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['# of neighbors','acc_train','acc_test']\n",
    "pd.DataFrame(r_performance, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Grid Searching for hyper-parameter tuning\n",
    "- sklearn.model.selection.GridSearchCV\n",
    "    - This function is included that both cross-validation and grid-searching.\n",
    "    - We want to use the grid searching to tune our hyper-parameters of model. In this case, we already have chosen knn\n",
    "    model. There is just one model we use. Therefore, we do not set the cv parameter of this function by default."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(estimator=KNeighborsClassifier(),\n             param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n       69, 70, 71])})"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_estimator = KNeighborsClassifier()\n",
    "iris_model_para = {'n_neighbors': np.arange(1, 72)}\n",
    "iris_grid = GridSearchCV(iris_estimator, param_grid=iris_model_para)\n",
    "iris_grid.fit(train_data, train_target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Show the grid-searching results\n",
    "- Best # of neighbor is 4\n",
    "- And 4 neighbors of knn model get a good score .98"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameter for # of neighbor for knn :  {'n_neighbors': 4}\n",
      "Best cv score based on the best para :  0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "print('Best hyper-parameter for # of neighbor for knn : ', iris_grid.best_params_)\n",
    "print('Best cv score based on the best para : ', iris_grid.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_grid.score(test_data, test_target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINST dataset:  dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "MINST_dataset = datasets.load_digits()\n",
    "print('MINST dataset: ', MINST_dataset.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MINST dataset description"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "print(MINST_dataset.DESCR)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pre-processing for images\n",
    "- There are two representations of images data\n",
    "    - Two dimensional representation: It's easier to understand and be used to visualization.\n",
    "    - One dimensional representation: It's suitable for training or learning. I think one dimension is more efficient\n",
    "    for algorithm because you do not need many layers in nested structure."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2 dimensional representation of image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 8, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(MINST_dataset.images.shape)\n",
    "MINST_dataset.images[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1 dimensional representation of image transformed from 2D\n",
    "- Length: 8 * 8 = 64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(MINST_dataset.data.shape)\n",
    "MINST_dataset.data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using matplotlib.plot.imgshow() to translate  a array to a image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x14ffaf73948>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "print(MINST_dataset.target[0])\n",
    "plt.imshow(MINST_dataset.images[0], cmap=plt.cm.gray_r, interpolation='nearest')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x14ffaf217c8>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(MINST_dataset.target[1])\n",
    "plt.imshow(MINST_dataset.images[1], cmap=plt.cm.gray_r, interpolation='nearest')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x14ffabbb848>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(MINST_dataset.target[2])\n",
    "plt.imshow(MINST_dataset.images[2], cmap=plt.cm.gray_r, interpolation='nearest')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- X: predictive variable\n",
    "- y: labed data(our target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "X = MINST_dataset.data\n",
    "y = MINST_dataset.target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Hold-out set for evaluation of model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Grid-searching for tuning hyper-parameter of model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "MINST_knn_estimator = KNeighborsClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(estimator=KNeighborsClassifier(),\n             param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MINST_model_para = {'n_neighbors': np.arange(1, 100)}\n",
    "MINST_knn_grid = GridSearchCV(MINST_knn_estimator, MINST_model_para)\n",
    "MINST_knn_grid.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 3}\n",
      "0.9867716802168023\n"
     ]
    }
   ],
   "source": [
    "print(MINST_knn_grid.best_params_)\n",
    "print(MINST_knn_grid.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "KNeighborsClassifier(n_neighbors=3)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MINST_knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "MINST_knn_model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360,)\n",
      "(360,)\n"
     ]
    }
   ],
   "source": [
    "MINST_predictions = MINST_knn_model.predict(X_test)\n",
    "MINST_true = y_test\n",
    "print(MINST_predictions.shape)\n",
    "print(MINST_true.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9861111111111112\n",
      "MacroAvg:  0.986027456027456\n",
      "MicroAvg:  0.9861111111111112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       0.97      1.00      0.99        36\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       0.95      0.97      0.96        37\n",
      "           4       1.00      0.97      0.99        36\n",
      "           5       1.00      1.00      1.00        37\n",
      "           6       1.00      1.00      1.00        36\n",
      "           7       0.97      1.00      0.99        36\n",
      "           8       1.00      0.94      0.97        35\n",
      "           9       0.97      0.97      0.97        36\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MINST_macro_avg = recall_score(MINST_true, MINST_predictions, average='macro')\n",
    "MINST_micro_avg = recall_score(MINST_true, MINST_predictions, average='micro')\n",
    "print('accuracy: ',MINST_knn_model.score(X_test, y_test))\n",
    "print('MacroAvg: ',MINST_macro_avg)\n",
    "print('MicroAvg: ',MINST_micro_avg)\n",
    "print(classification_report(MINST_true, MINST_predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}